{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [], 1: [52, 73, 234, 265], 2: [156, 263], 3: [263, 295, 156], 4: [70, 201], 5: [194, 252], 6: [46], 7: [145, 188], 8: [124, 264], 9: [31, 232], 10: [95, 128], 11: [163, 212, 83, 104, 28, 249, 94], 12: [56, 257], 13: [156, 250, 225, 157, 167, 279], 14: [92, 167], 15: [78, 269], 16: [91, 173], 17: [110, 293, 74], 18: [186, 193], 19: [97], 20: [65, 217], 21: [67, 269], 22: [47, 111], 23: [41, 157], 24: [156, 164], 25: [161, 255], 26: [260, 274], 27: [79, 201], 28: [162, 192, 11, 107], 29: [84, 157], 30: [176, 190], 31: [9, 303], 32: [70, 204], 33: [36, 164], 34: [100, 119], 35: [245], 36: [33, 289], 37: [158, 301], 38: [58, 81], 39: [128, 145], 40: [47, 89, 139, 170], 41: [216, 253, 23, 42], 42: [120, 292, 41, 183], 43: [79, 219, 183, 289], 44: [161, 166], 45: [207, 243], 46: [6, 50, 53], 47: [22, 40], 48: [126, 250], 49: [87, 197, 151], 50: [46], 51: [103, 215], 52: [1, 265], 53: [46, 214], 54: [55, 56], 55: [54, 245], 56: [12, 54], 57: [187], 58: [38, 119], 59: [240, 258], 60: [126, 151], 61: [171, 238], 62: [168, 280], 63: [203, 219], 64: [106, 135], 65: [20, 97], 66: [67, 85], 67: [21, 66], 68: [158, 256], 69: [86, 106], 70: [4, 32], 71: [172, 297], 72: [286, 73], 73: [72, 1, 182], 74: [99, 122, 138, 287, 293, 17], 75: [210, 222], 76: [181, 296], 77: [93, 124], 78: [15, 270], 79: [27, 43], 80: [205, 231], 81: [38], 82: [163, 193], 83: [11, 193], 84: [148, 29, 136], 85: [66, 129], 86: [69, 152], 87: [49, 279, 255, 285], 88: [256], 89: [40, 145, 170, 277], 90: [104, 145], 91: [16, 109], 92: [14, 145], 93: [77, 165, 288], 94: [254, 290, 11, 282], 95: [10, 160, 123, 224], 96: [195, 287], 97: [19, 65], 98: [173, 211], 99: [122, 236, 74], 100: [34, 111], 101: [110, 227], 102: [259, 277], 103: [51, 109], 104: [11, 90], 105: [177, 196], 106: [64, 69], 107: [28, 285, 133, 197, 192, 273], 108: [141, 265], 109: [91, 103], 110: [17, 209, 101, 265], 111: [22, 100], 112: [181, 196], 113: [246, 298], 114: [140], 115: [178, 184, 291], 116: [117, 118, 132], 117: [116, 118], 118: [116, 117], 119: [34, 58], 120: [42, 238], 121: [261], 122: [99, 186, 74], 123: [95, 145], 124: [8, 77], 125: [134, 271], 126: [48, 259, 60, 223], 127: [186, 226], 128: [10, 39], 129: [85, 268], 130: [131, 132], 131: [130, 190], 132: [116, 130], 133: [107, 146], 134: [125, 220], 135: [64, 171], 136: [84, 191, 279], 137: [206, 298], 138: [74], 139: [40, 264], 140: [114, 237], 141: [108, 213], 142: [290, 297], 143: [159, 206], 144: [207, 282], 145: [90, 92, 7, 89, 39, 223, 123], 146: [133, 236], 147: [150, 283], 148: [84, 279], 149: [162, 208], 150: [147, 227], 151: [49, 259, 60, 197], 152: [86], 153: [154, 247], 154: [153, 230, 275], 155: [225, 284], 156: [13, 24, 2, 167, 3], 157: [23, 233, 13, 29], 158: [37, 68], 159: [143, 278], 160: [95, 266], 161: [25, 44], 162: [28, 149], 163: [11, 82], 164: [24, 247, 33, 244], 165: [93], 166: [44, 263], 167: [14, 156, 13, 188], 168: [62, 179, 214], 169: [240], 170: [40, 89], 171: [61, 135], 172: [71, 282], 173: [16, 98], 174: [253], 175: [253], 176: [30, 234], 177: [105, 239], 178: [115, 202], 179: [168, 180], 180: [179, 199], 181: [76, 112, 286], 182: [73, 194], 183: [42, 43], 184: [115, 199], 185: [237, 281], 186: [127, 208, 18, 122], 187: [57, 232], 188: [7, 167], 189: [], 190: [30, 131], 191: [136, 245], 192: [197, 212, 28, 259, 107, 277], 193: [82, 278, 18, 83, 218], 194: [5, 182], 195: [96, 205], 196: [105, 112], 197: [49, 192, 107, 151], 198: [272, 273], 199: [180, 184], 200: [270, 289], 201: [4, 27, 284, 292], 202: [178, 282], 203: [63, 217], 204: [32, 247], 205: [80, 195], 206: [137, 143], 207: [45, 144], 208: [149, 186], 209: [110, 242], 210: [75, 291, 235], 211: [98, 275], 212: [11, 192], 213: [141], 214: [53, 168], 215: [51, 301], 216: [41, 276], 217: [20, 203], 218: [193, 283], 219: [43, 63], 220: [134, 222], 221: [239, 294], 222: [75, 220], 223: [126, 145], 224: [95, 260], 225: [13, 155, 262, 276, 295], 226: [127, 296], 227: [101, 150], 228: [295], 229: [236, 273], 230: [154, 241], 231: [80, 300], 232: [9, 187], 233: [157, 279], 234: [1, 176], 235: [210, 251], 236: [99, 229, 146], 237: [140, 185], 238: [61, 120], 239: [177, 221], 240: [59, 169], 241: [230, 301], 242: [209, 265], 243: [45], 244: [164, 295], 245: [55, 191, 35, 272], 246: [113, 281], 247: [153, 164, 204, 289], 248: [273, 285], 249: [11, 254], 250: [13, 48], 251: [235, 252], 252: [5, 251], 253: [41, 174, 175], 254: [94, 249], 255: [25, 87], 256: [68, 88], 257: [12, 258], 258: [59, 257], 259: [126, 192, 102, 151], 260: [26, 224], 261: [121, 302], 262: [225], 263: [2, 166, 3], 264: [8, 139], 265: [52, 108, 242, 1, 110], 266: [160, 303], 267: [268], 268: [129, 267], 269: [15, 21], 270: [78, 200], 271: [125], 272: [198, 245], 273: [229, 248, 107, 198], 274: [26], 275: [154, 211], 276: [216, 225], 277: [89, 102, 192], 278: [159, 193], 279: [87, 148, 233, 285, 136, 13], 280: [62], 281: [185, 246], 282: [144, 172, 94, 202], 283: [147, 218], 284: [155, 201, 292], 285: [87, 248, 107, 279], 286: [72, 181], 287: [74, 96], 288: [93, 302], 289: [36, 200, 43, 247], 290: [94, 142], 291: [115, 210], 292: [42, 201, 284], 293: [17, 74], 294: [221], 295: [3, 244, 225, 228], 296: [76, 226], 297: [71, 142], 298: [113, 137], 299: [300], 300: [231, 299], 301: [37, 215, 241], 302: [261, 288], 303: [31, 266]}\n",
      "0.02715326867984767\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "import math\n",
    "\n",
    "\n",
    "class WeightedGraph: \n",
    "    # using adjacency list\n",
    "    def __init__(self, nodes):\n",
    "        self.graph = {} #Dictionary to store adjacency lists for each node.\n",
    "        self.weight={} #Dictionary to store weights of edges \n",
    "        for i in range(nodes): #because station starts from id 1 \n",
    "            self.graph[i] = []\n",
    "        \n",
    "    def has_edge(self, src, dst):\n",
    "        return dst in self.graph[src]\n",
    "    \n",
    "    def add_edge(self,src,dst,weight):\n",
    "\n",
    "        if not self.has_edge(src,dst): #Prevent duplicate edges \n",
    "            self.graph[src].append(dst)\n",
    "            self.weight[(src,dst)]=weight\n",
    "\n",
    "            self.graph[dst].append(src)\n",
    "            self.weight[(dst,src)]= weight #Store weight for both directions \n",
    "\n",
    "\n",
    "    def get_total_weight(self,):\n",
    "        total = 0\n",
    "        for src, neighbors in enumerate(self.graph): #src: current node, enumerate - 0 value, 1 value, 2 value..\n",
    "            for dst in neighbors: #src value is fixed, dst is iterated within neighbors until its done. \n",
    "                    total+= self.weight[(src,dst)]\n",
    "\n",
    "        return total/2 #Divide by 2 to avoid double counting (ex: 0->1 and 1->0, they are the same.)\n",
    "\n",
    "    def get_graph(self,):\n",
    "        return self.graph\n",
    "    \n",
    "\n",
    "    #get the weight of the edge between node1 and node2.\n",
    "    def get_weight(self, node1, node2):\n",
    "        if (node1,node2) in self.weight:\n",
    "            return self.weight[(node1,node2)]\n",
    "        else:\n",
    "            return \"No distance: Station1 and Station2 are not neighbors\"\n",
    "        \n",
    "    \n",
    "    def get_size(self,):\n",
    "        return len(self.graph)  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def calculate_euclidean_distance(lat1, lon1, lat2, lon2):\n",
    "    return math.sqrt((lat2 - lat1) ** 2 + (lon2 - lon1) ** 2)\n",
    "\n",
    "def build_tube_graph_from_stations_and_connections(stations_csv, connections_csv):\n",
    " \n",
    "    # Parse stations data (from stations CSV)---------------------------------------------------------\n",
    "    stations = {}\n",
    "    csv_reader = csv.reader(StringIO(stations_csv))\n",
    "    next(csv_reader)  # Skip header row\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        if not row or len(row) < 8:\n",
    "            continue\n",
    "        \n",
    "        station_id = int(row[0])\n",
    "        lat = float(row[1]) if row[1] else None\n",
    "        lon = float(row[2]) if row[2] else None\n",
    "        name = row[3].strip('\"')\n",
    "        display_name = row[4].strip('\"') if row[4] and row[4] != \"NULL\" else name\n",
    "        zone = row[6]\n",
    "        total_lines = int(row[7]) if row[7] else 0\n",
    "        rail = int(row[8]) if len(row) > 8 and row[8] else 0\n",
    "        \n",
    "        stations[station_id] = {\n",
    "            \"id\": station_id,\n",
    "            \"name\": name,\n",
    "            \"display_name\": display_name,\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"zone\": zone,\n",
    "            \"total_lines\": total_lines,\n",
    "            \"rail\": rail,\n",
    "        }\n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Create the graph with number of stations\n",
    "    max_station_id = max(stations.keys()) if stations else 0\n",
    "    graph = WeightedGraph(max_station_id + 1)\n",
    "    \n",
    "    # Parse connections data (from connections CSV)\n",
    "    csv_reader = csv.reader(StringIO(connections_csv))\n",
    "    next(csv_reader)  # Skip header row\n",
    "\n",
    "    # Now connect each station based on the provided connections\n",
    "    for row in csv_reader:\n",
    "        if not row or len(row) < 4:\n",
    "            continue\n",
    "        \n",
    "        station1_id = int(row[0])\n",
    "        station2_id = int(row[1])\n",
    "        \n",
    "        # Check if both stations exist in the station dictionary\n",
    "        if station1_id in stations and station2_id in stations:\n",
    "            lat1, lon1 = stations[station1_id][\"lat\"], stations[station1_id][\"lon\"]\n",
    "            lat2, lon2 = stations[station2_id][\"lat\"], stations[station2_id][\"lon\"]\n",
    "            \n",
    "            # Calculate Euclidean distance between the stations\n",
    "            if lat1 is not None and lon1 is not None and lat2 is not None and lon2 is not None:\n",
    "                distance = calculate_euclidean_distance(lat1, lon1, lat2, lon2)\n",
    "                graph.weight[(station1_id,station2_id)]= distance\n",
    "                \n",
    "                # Add the edge to the graph with time as weight\n",
    "                graph.add_edge(station1_id, station2_id, distance)\n",
    "    \n",
    "    return graph, stations\n",
    "\n",
    "# Read the CSV files\n",
    "with open(\"london_stations.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    stations_csv = file.read()\n",
    "\n",
    "with open(\"london_connections.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    connections_csv = file.read()\n",
    "\n",
    "# Run the function\n",
    "graph, stations = build_tube_graph_from_stations_and_connections(stations_csv, connections_csv) \n",
    "print(graph.get_graph())  \n",
    "print(graph.get_weight(1,234)) \n",
    "   \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
